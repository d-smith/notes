scala> val licLines = sc.textFile("LICENSE")
licLines: org.apache.spark.rdd.RDD[String] = LICENSE MapPartitionsRDD[3] at textFile at <console>:27

scala> val lineCnt = licLines.count
lineCnt: Long = 294

scala> val bsdLines = licLines.filter(line => line.contains("BSD"))
bsdLines: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[4] at filter at <console>:29

scala> bsdLines.count
res1: Long = 34

scala> bsdLines.foreach(println)
...

val numbers = sc.parallelize(10 to 50 by 10)
numbers.foreach(println)
val numbersSquared = numbers.map(x => x*x)
numbersSquared.foreach(println)

MACLB015803:spark a045103$ cat client-ids.log 
15,16,20,20
77,80,94
94,98,16,31
31,15,20

val lines = sc.textFile("client-ids.log")
val idsStr = lines.map(line => line.split(","))
idsStr
idsStr.foreach(println)
idsStr.first
idsStr.collect
val ids = lines.flatMap(_.split(","))
ids.collect
ids.collect.mkstring("; ")
ids.collect.mkString("; ")
val intIds = ids.map(_.toInt)
intIds.collect
:history
val uniqueIds = intIds.distinct
uniqueIds.collect
intIds.mean
intIds.sum

